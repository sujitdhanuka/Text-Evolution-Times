{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6a64a1-819a-4ca1-afaa-2063d47aa2ee",
   "metadata": {},
   "source": [
    "# Conditional Random Fields\n",
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50761bf3-ea3a-4459-a2b2-e4fdb25bcd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.73      0.71      0.72       446\n",
      "      B-MISC       0.78      0.48      0.59       197\n",
      "       B-ORG       0.68      0.35      0.46       523\n",
      "       B-PER       0.73      0.74      0.74       672\n",
      "       I-LOC       0.89      0.46      0.60        68\n",
      "      I-MISC       0.64      0.65      0.65        83\n",
      "       I-ORG       0.60      0.40      0.48       223\n",
      "       I-PER       0.74      0.94      0.83       493\n",
      "           O       0.95      0.98      0.97      9440\n",
      "\n",
      "    accuracy                           0.91     12145\n",
      "   macro avg       0.75      0.63      0.67     12145\n",
      "weighted avg       0.90      0.91      0.90     12145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report, flatten\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "sample_size = 1000\n",
    "# Load CoNLL-2003 dataset\n",
    "dataset = datasets.load_dataset('conll2003', trust_remote_code=True)\n",
    "\n",
    "train_tokens = dataset[\"train\"][\"tokens\"][:sample_size]\n",
    "train_tags = dataset[\"train\"][\"ner_tags\"][:sample_size]\n",
    "\n",
    "test_tokens = dataset[\"test\"][\"tokens\"][:sample_size]\n",
    "test_tags = dataset[\"test\"][\"ner_tags\"][:sample_size]\n",
    "\n",
    "#converting the integer values of ner_tags to their coressponding ner_tag values as the dictionary given in data description\n",
    "def int_ner(data):\n",
    "    d = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "\n",
    "    d1 = {v:k for k, v in d.items()}\n",
    "    i=0\n",
    "    for elements in data:\n",
    "        for j in range(len(elements)):\n",
    "            data[i][j] = d1[elements[j]]\n",
    "        i+=1\n",
    "    return data\n",
    "\n",
    "train_tags = int_ner(train_tags)\n",
    "test_tabs = int_ner(test_tags)\n",
    "# Feature extraction functions\n",
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of Sentence\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of Sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return sent\n",
    "\n",
    "# Prepare data\n",
    "X_train = [sent2features(s) for s in train_tokens]\n",
    "y_train = train_tags\n",
    "X_test = [sent2features(s) for s in test_tokens]\n",
    "y_test = test_tags\n",
    "\n",
    "# Train CRF\n",
    "crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(flatten(y_test), flatten(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac723c-e705-42c6-ae94-80b42433560e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
