{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd3a47e-27e9-405a-84b3-c8c957a6ee50",
   "metadata": {},
   "source": [
    "# Hidden Markov Models (HMM) for POS tagging\n",
    "Here's a basic example to illustrate the use of an HMM for POS tagging. We'll use a simplified dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "921fbd35-3216-4ba2-8652-99af213f1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required Libraries\n",
    "#!pip install hmmlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2facc601-ed95-4716-b418-a605f94a0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: eat, banana, flies, like\n",
      "Predicted States: Verb, Noun, Noun, Noun\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Define states (POS tags) and observations (words)\n",
    "states = ['Noun', 'Verb']\n",
    "observations = ['eat', 'banana', 'flies', 'like', ]\n",
    "\n",
    "# Define the start probability vector\n",
    "start_probability = np.array([0.5, 0.5])\n",
    "\n",
    "# Define the transition probability matrix between states\n",
    "transition_probability = np.array([\n",
    "  [0.7, 0.3],  # Noun -> Noun, Noun -> Verb\n",
    "  [0.4, 0.6],  # Verb -> Noun, Verb -> Verb\n",
    "])\n",
    "\n",
    "# Define the emission probability matrix (probability of observation given state)\n",
    "emission_probability = np.array([\n",
    "  [0.1, 0.4, 0.1, 0.4],  # P(eat|Noun), P(banana|Noun), ...\n",
    "  [0.4, 0.1, 0.4, 0.1],  # P(eat|Verb), P(banana|Verb), ...\n",
    "])\n",
    "\n",
    "\n",
    "# Create HMM instance with Multinomial distribution\n",
    "model = hmm.CategoricalHMM(n_components=len(states))\n",
    "model.startprob_ = start_probability\n",
    "model.transmat_ = transition_probability\n",
    "model.emissionprob_ = emission_probability\n",
    "model.n_trials=10\n",
    "\n",
    "# Encode the observations\n",
    "observation_sequence = np.array([[0, 1, 2, 3]]) # 'eat', 'banana', 'flies', 'like'\n",
    "\n",
    "# Predict the states for the observation\n",
    "logprob, states_prob = model.decode(observation_sequence, algorithm=\"viterbi\")\n",
    "print(\"Observations:\", ', '.join(observations[idx] for idx in observation_sequence.flatten()))\n",
    "print(\"Predicted States:\", ', '.join(states[i] for i in states_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938e31d-d67b-4563-9c94-2a8c5c626627",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- **States and Observations**: We define the possible states (POS tags) and observations (words) for our model.\n",
    "- **Start Probability**: This is the probability of starting in each state.\n",
    "- **Transition Probability**: This matrix defines the probability of transitioning from one state to another.\n",
    "- **Emission Probability**: This matrix gives the probability of observing each word given a particular state.\n",
    "- **Model Setup**: We initialize the HMM with the number of states (n_components) and set the defined probabilities.\n",
    "- **Prediction**: We predict the sequence of states for a given sequence of words using the Viterbi algorithm, which is a dynamic programming approach to finding the most likely sequence of hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d7a7e-56fc-4cbf-bb4e-377ff5284d6c",
   "metadata": {},
   "source": [
    "# Conditional Random Fields (CRFs) \n",
    "\n",
    "**Conditional Random Fields (CRFs)** are a class of statistical modeling methods often used in pattern recognition and machine learning, where they are commonly applied to structured prediction tasks like sequence labeling and part-of-speech tagging in Natural Language Processing (NLP). CRFs are particularly useful for tasks that require taking context into account, making them more sophisticated than models that treat input features independently.\n",
    "\n",
    "\n",
    "## Python Code for NER Using CRF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18ec19f-64be-44d5-8c92-bacc5e6de86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'B-PER'), ('Smith', 'I-PER'), ('works', 'O'), ('at', 'O'), ('Google', 'B-ORG')]\n",
      "[('The', 'O'), ('office', 'O'), ('is', 'O'), ('in', 'O'), ('New', 'B-LOC'), ('York', 'I-LOC')]\n",
      "[('She', 'O'), ('traveled', 'O'), ('to', 'O'), ('Paris', 'B-LOC')]\n",
      "[('IBM', 'B-ORG'), ('is', 'O'), ('a', 'O'), ('large', 'O'), ('company', 'O')]\n",
      "[('Mark', 'B-PER'), ('and', 'O'), ('Sarah', 'B-PER'), ('visited', 'O'), ('Microsoft', 'B-ORG')]\n",
      "[('Hello', 'O'), ('World', 'O')]\n"
     ]
    }
   ],
   "source": [
    "## INSTALL THE REQUIRED LIBRARY\n",
    "#!pip install sklearn-crfsuite scikit-learn\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "def word2features(sent, i):\n",
    "    \"\"\" Function to extract features from each word in the sentence \"\"\"\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of Sentence\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of Sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    \"\"\" Extract features from a sentence \"\"\"\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    \"\"\" Extract labels from a sentence \"\"\"\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    \"\"\" Extract tokens from a sentence \"\"\"\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# Example sentence\n",
    "sentences = [\n",
    "    [(\"John\", \"NNP\", \"B-PER\"), (\"Smith\", \"NNP\", \"I-PER\"), (\"works\", \"VBZ\", \"O\"), (\"at\", \"IN\", \"O\"), (\"Google\", \"NNP\", \"B-ORG\")],\n",
    "    [(\"The\", \"DT\", \"O\"), (\"office\", \"NN\", \"O\"), (\"is\", \"VBZ\", \"O\"), (\"in\", \"IN\", \"O\"), (\"New\", \"NNP\", \"B-LOC\"), (\"York\", \"NNP\", \"I-LOC\")],\n",
    "    [(\"She\", \"PRP\", \"O\"), (\"traveled\", \"VBD\", \"O\"), (\"to\", \"TO\", \"O\"), (\"Paris\", \"NNP\", \"B-LOC\")],\n",
    "    [(\"IBM\", \"NNP\", \"B-ORG\"), (\"is\", \"VBZ\", \"O\"), (\"a\", \"DT\", \"O\"), (\"large\", \"JJ\", \"O\"), (\"company\", \"NN\", \"O\")],\n",
    "    [(\"Mark\", \"NNP\", \"B-PER\"), (\"and\", \"CC\", \"O\"), (\"Sarah\", \"NNP\", \"B-PER\"), (\"visited\", \"VBD\", \"O\"), (\"Microsoft\", \"NNP\", \"B-ORG\")],\n",
    "    [(\"Hello\", \"NNP\", \"O\"), (\"World\", \"NNP\", \"O\")],  \n",
    "]\n",
    "\n",
    "# Extract features\n",
    "# Extract features and labels from the dataset\n",
    "X_train = [sent2features(s) for s in sentences]\n",
    "y_train = [sent2labels(s) for s in sentences]\n",
    "\n",
    "# Train the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0,\n",
    "    c2=.11,\n",
    "    max_iterations=1000,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the same sentence\n",
    "y_pred = crf.predict(X_train)\n",
    "\n",
    "for sent, labels in zip(sentences, y_pred):\n",
    "    print([(word[0], label) for word, label in zip(sent, labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58f4ba0-bd61-4d74-8857-af934f2ff350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Larry', 'O'), ('Page', 'O'), ('founded', 'O'), ('Google', 'B-ORG')]\n",
      "[('The', 'O'), ('beautiful', 'O'), ('city', 'O'), ('of', 'O'), ('Rome', 'B-ORG')]\n"
     ]
    }
   ],
   "source": [
    "# New test sentences\n",
    "test_sentences = [\n",
    "    [(\"Larry\", \"NNP\", \"B-PER\"), (\"Page\", \"NNP\", \"I-PER\"), (\"founded\", \"VBD\", \"O\"), (\"Google\", \"NNP\", \"B-ORG\")],\n",
    "    [(\"The\", \"DT\", \"O\"), (\"beautiful\", \"JJ\", \"O\"), (\"city\", \"NN\", \"O\"), (\"of\", \"IN\", \"O\"), (\"Rome\", \"NNP\", \"B-LOC\")]\n",
    "]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sentences]\n",
    "y_test = [sent2labels(s) for s in test_sentences]\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "for sent, labels in zip(test_sentences, y_pred):\n",
    "    print([(word[0], label) for word, label in zip(sent, labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5afd87-0479-4763-b0f0-d00cf76134a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
